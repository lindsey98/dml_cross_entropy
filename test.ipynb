{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "619c21a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data.dataset_ingredient import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from utils.training import *\n",
    "from utils.training import evaluate, _Metrics\n",
    "from models.ingredient import model_ingredient, get_model\n",
    "from utils.metrics import recall_at_ks_full, fp_fn_eval\n",
    "import torch\n",
    "from torch import nn\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from fastdist import fastdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c6485f",
   "metadata": {},
   "source": [
    "## Re-split dataset into train/pool/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "c4212140",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = open('data/InShop/train.txt').readlines()\n",
    "# test_data = open('data/Stanford_Online_Products/test.txt').readlines()\n",
    "test_data = open('data/InShop/test_gallery.txt').readlines() + open('data/InShop/test_query.txt').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6d180bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split some training into query+testing \n",
    "# train_imgs = [x.strip().split(',')[0] for x in train_data]\n",
    "# train_labels = [x.strip().split(',')[1] for x in train_data]\n",
    "\n",
    "# # split into testing and query \n",
    "# test_imgs = [x.strip().split(',')[0] for x in test_data]\n",
    "# test_labels = [x.strip().split(',')[1] for x in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e271ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train_data + test_data\n",
    "all_imgs = [x.strip().split(',')[0] for x in all_data]\n",
    "all_labels = [int(x.strip().split(',')[1]) for x in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "e537d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all few-shot classes are included in training\n",
    "fewshot = {k: Counter(all_labels)[k] for k in Counter(all_labels).keys() if Counter(all_labels)[k] <= 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "36bc4d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3941 7982\n"
     ]
    }
   ],
   "source": [
    "fewshot_class = list(fewshot.keys())\n",
    "print(len(fewshot_class), len(list(Counter(all_labels).keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "b39d19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keep_data = np.asarray(all_data)[np.isin(np.asarray(all_labels), fewshot_class)]\n",
    "train_imgs = [x.strip().split(',')[0] for x in train_keep_data]\n",
    "train_labels = [int(x.strip().split(',')[1]) for x in train_keep_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b1c7489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keep_imgs, train_left_imgs, train_keep_labels, train_left_labels = train_test_split(train_imgs, train_labels, \n",
    "                                                                                        test_size=0.4, \n",
    "                                                                                        random_state=42, \n",
    "#                                                                                         stratify=train_labels  \n",
    "                                                                                         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "21c200b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/InShop/train_small.txt', 'w') as f:\n",
    "    pass\n",
    "\n",
    "for j in range(len(train_keep_imgs)):\n",
    "    with open('data/InShop/train_small.txt', 'a+') as f:\n",
    "        f.write(train_keep_imgs[j] + ',' + str(train_keep_labels[j]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ecab731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into testing and query \n",
    "query_imgs = train_left_imgs\n",
    "query_labels = train_left_labels\n",
    "test_imgs = np.asarray(all_imgs)[(~np.isin(np.asarray(all_imgs), train_keep_imgs))&(~np.isin(np.asarray(all_imgs), query_imgs))]\n",
    "test_labels = np.asarray(all_labels)[(~np.isin(np.asarray(all_imgs), train_keep_imgs))&(~np.isin(np.asarray(all_imgs), query_imgs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "7374bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_extra_imgs, test_keep_imgs, query_extra_labels, test_keep_labels = train_test_split(test_imgs, test_labels, \n",
    "                                                                              test_size=0.5, \n",
    "                                                                              random_state=42, \n",
    "                                                                              stratify=test_labels,\n",
    "                                                                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "4eb5297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/InShop/pool.txt', 'w') as f:\n",
    "    pass\n",
    "\n",
    "for j in range(len(query_imgs)):\n",
    "    with open('data/InShop//pool.txt', 'a+') as f:\n",
    "        f.write(query_imgs[j] + ',' + str(query_labels[j]) + '\\n')\n",
    "        \n",
    "for j in range(len(query_extra_imgs)):\n",
    "    with open('data/InShop//pool.txt', 'a+') as f:\n",
    "        f.write(query_extra_imgs[j] + ',' + str(query_extra_labels[j]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "ed5a5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/InShop/test_new.txt', 'w') as f:\n",
    "    pass\n",
    "\n",
    "for j in range(len(test_keep_imgs)):\n",
    "    with open('data/InShop/test_new.txt', 'a+') as f:\n",
    "        f.write(test_keep_imgs[j] + ',' + str(test_keep_labels[j]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d9621f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training: 20080\n",
      "Num query: 56680\n",
      "Num test: 43293\n"
     ]
    }
   ],
   "source": [
    "print('Num training: {}'.format(len(open('data/Stanford_Online_Products/train_small.txt').readlines())))\n",
    "print('Num query: {}'.format(len(open('data/Stanford_Online_Products/pool.txt').readlines())))\n",
    "print('Num test: {}'.format(len(open('data/Stanford_Online_Products/test_new.txt').readlines())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1606f389",
   "metadata": {},
   "source": [
    "## Check class balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "cd3b2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = open('data/InShop/train_small.txt').readlines()\n",
    "test_data = open('data/InShop/test_new.txt').readlines()\n",
    "pool_data = open('data/InShop/pool.txt').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "610f5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = [int(x.strip().split(',')[1]) for x in train_data]\n",
    "test_classes = [int(x.strip().split(',')[1]) for x in test_data]\n",
    "pool_classes = [int(x.strip().split(',')[1]) for x in pool_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "79e4b7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.bar(x=Counter(test_classes).keys(), height=Counter(test_classes).values())\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylim(top=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fedd56",
   "metadata": {},
   "source": [
    "## Load configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95cf2f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_config = data_ingredient.configurations[0]()\n",
    "data_config = data_ingredient.named_configs['cub']() # experiment's config\n",
    "# data_config = data_ingredient.named_configs['inshop_vae']() # experiment's config\n",
    "\n",
    "\n",
    "train_file = data_config['train_file'] if 'train_file' in data_config.keys() else general_config['train_file']\n",
    "test_file = data_config['test_file'] if 'test_file' in data_config.keys() else general_config['test_file']\n",
    "pool_file = data_config['pool_file'] if 'pool_file' in data_config.keys() else general_config['pool_file']\n",
    "sampler = general_config['sampler']\n",
    "batch_size = general_config['batch_size']\n",
    "test_batch_size = general_config['test_batch_size']\n",
    "preload = general_config['preload']\n",
    "num_workers = general_config['num_workers']\n",
    "pin_memory = general_config['pin_memory']\n",
    "scale = general_config['scale']\n",
    "ratio = general_config['ratio']\n",
    "recalls = general_config['recalls']\n",
    "\n",
    "name = data_config['name']\n",
    "data_path = data_config['data_path']\n",
    "resize = data_config['resize'] if 'resize' in data_config.keys() else None\n",
    "rotate = data_config['rotate'] if 'rotate' in data_config.keys() else None\n",
    "color_jitter = data_config['color_jitter'] if 'color_jitter' in data_config.keys() else None\n",
    "crop_size = data_config['crop_size'] if 'crop_size' in data_config.keys() else general_config['crop_size']\n",
    "\n",
    "\n",
    "scale = data_config['scale'] if 'scale' in data_config.keys() else scale\n",
    "ratio = data_config['ratio'] if 'ratio' in data_config.keys() else ratio\n",
    "recalls = data_config['recalls'] if 'recalls' in data_config.keys() else recalls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "233aa254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(name, data_path, train_file, test_file, pool_file, preload, num_workers):\n",
    "    train_transform, test_transform = get_transforms(crop_size, \n",
    "                                                     scale, ratio, \n",
    "                                                     resize, rotate, \n",
    "                                                     color_jitter)\n",
    "\n",
    "    train_lines = read_file(os.path.join(data_path, train_file))\n",
    "    train_samples = [(os.path.join(data_path, line.split(',')[0]), int(line.split(',')[1])) for line in train_lines]\n",
    "    known_classes = [int(line.split(',')[1]) for line in train_lines]\n",
    "    train_set = ImageDataset(train_samples, transform=train_transform, \n",
    "                             preload=preload, num_workers=num_workers)\n",
    "\n",
    "    query_lines = read_file(os.path.join(data_path, test_file))\n",
    "    query_samples = [(os.path.join(data_path, line.split(',')[0]), int(line.split(',')[1])) for line in query_lines]\n",
    "    query_set = ImageDataset(query_samples, transform=test_transform, preload=preload, num_workers=num_workers)\n",
    "    gallery_set = None\n",
    "        \n",
    "    # test set which only includes novel classes\n",
    "    query_novel_samples = [(os.path.join(data_path, line.split(',')[0]), int(line.split(',')[1])) \\\n",
    "                               for line in query_lines if int(line.split(',')[1]) not in known_classes]  \n",
    "    query_novel_set = ImageDataset(query_novel_samples, transform=test_transform, \n",
    "                                   preload=preload, num_workers=num_workers)\n",
    "\n",
    "    # pool set\n",
    "    pool_lines = read_file(os.path.join(data_path, pool_file))\n",
    "    pool_samples = [(os.path.join(data_path, line.split(',')[0]), int(line.split(',')[1])) for line in pool_lines]\n",
    "    pool_set = ImageDataset(pool_samples, transform=test_transform, preload=preload, num_workers=num_workers)\n",
    "\n",
    "    return train_set, (query_set, gallery_set, pool_set, query_novel_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d32f038",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_loaders(batch_size, test_batch_size, num_workers, pin_memory, sampler, recalls,\n",
    "                num_iterations=None, num_identities=None):\n",
    "    \n",
    "    train_set, (query_set, gallery_set, pool_set, query_novel_set) = get_sets(name, data_path, \n",
    "                                                             train_file, test_file, pool_file,\n",
    "                                                             preload, num_workers)\n",
    "\n",
    "    if sampler == 'random':\n",
    "        train_sampler = BatchSampler(RandomSampler(train_set), batch_size=batch_size, drop_last=True)\n",
    "    elif sampler == 'random_id':\n",
    "        train_sampler = RandomReplacedIdentitySampler(train_set.targets, batch_size, num_identities, num_iterations)\n",
    "    else:\n",
    "        raise ValueError('Invalid choice of sampler ({}).'.format(sampler))\n",
    "    train_loader = DataLoader(train_set, batch_sampler=train_sampler, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    train_noshuffle = DataLoader(train_set, batch_size=test_batch_size,num_workers=num_workers, pin_memory=pin_memory)\n",
    "    query_loader = DataLoader(query_set, batch_size=test_batch_size, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    gallery_loader = None\n",
    "    if gallery_set is not None:\n",
    "        gallery_loader = DataLoader(gallery_set, batch_size=test_batch_size, num_workers=num_workers,\n",
    "                                    pin_memory=pin_memory)\n",
    "        \n",
    "    query_novel_loader = DataLoader(query_novel_set, batch_size=test_batch_size, \n",
    "                                    num_workers=num_workers, pin_memory=pin_memory)\n",
    "    \n",
    "    # label is not continuous, need this dictionary to map it to continuous integer\n",
    "    labeldict = {}\n",
    "    i = 0\n",
    "    for label in set(train_set.targets):\n",
    "        if int(label) not in labeldict.keys():\n",
    "            labeldict[int(label)] = i\n",
    "            i += 1\n",
    "            \n",
    "    for label in set(pool_set.targets):\n",
    "        if int(label) not in labeldict.keys():\n",
    "            labeldict[int(label)] = i\n",
    "            i += 1\n",
    "            \n",
    "    for label in set(query_set.targets):\n",
    "        if int(label) not in labeldict.keys():\n",
    "            labeldict[int(label)] = i\n",
    "            i += 1\n",
    " \n",
    "    print(labeldict)\n",
    "    \n",
    "    pool_loader = DataLoader(pool_set, batch_size=test_batch_size, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    return MetricLoaders(train=train_loader, query=query_loader, pool=pool_loader, gallery=gallery_loader, \n",
    "                         train_noshuffle = train_noshuffle,\n",
    "                         num_classes=len(set(train_set.targets)),\n",
    "                         labeldict=labeldict,\n",
    "                         query_novel=query_novel_loader), recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "583a08b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19, 20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38, 39: 39, 40: 40, 41: 41, 42: 42, 43: 43, 44: 44, 45: 45, 46: 46, 47: 47, 48: 48, 49: 49, 50: 50, 51: 51, 52: 52, 53: 53, 54: 54, 55: 55, 56: 56, 57: 57, 58: 58, 59: 59, 60: 60, 61: 61, 62: 62, 63: 63, 64: 64, 65: 65, 66: 66, 67: 67, 68: 68, 69: 69, 70: 70, 71: 71, 72: 72, 73: 73, 74: 74, 75: 75, 76: 76, 77: 77, 78: 78, 79: 79, 80: 80, 81: 81, 82: 82, 83: 83, 84: 84, 85: 85, 86: 86, 87: 87, 88: 88, 89: 89, 90: 90, 91: 91, 92: 92, 93: 93, 94: 94, 95: 95, 96: 96, 97: 97, 98: 98, 99: 99, 100: 100, 101: 101, 102: 102, 103: 103, 104: 104, 105: 105, 106: 106, 107: 107, 108: 108, 109: 109, 110: 110, 111: 111, 112: 112, 113: 113, 114: 114, 115: 115, 116: 116, 117: 117, 118: 118, 119: 119, 120: 120, 121: 121, 122: 122, 123: 123, 124: 124, 125: 125, 126: 126, 127: 127, 128: 128, 129: 129, 130: 130, 131: 131, 132: 132, 133: 133, 134: 134, 135: 135, 136: 136, 137: 137, 138: 138, 139: 139, 140: 140, 141: 141, 142: 142, 143: 143, 144: 144, 145: 145, 146: 146, 147: 147, 148: 148, 149: 149, 150: 150, 151: 151, 152: 152, 153: 153, 154: 154, 155: 155, 156: 156, 157: 157, 158: 158, 159: 159, 160: 160, 161: 161, 162: 162, 163: 163, 164: 164, 165: 165, 166: 166, 167: 167, 168: 168, 169: 169, 170: 170, 171: 171, 172: 172, 173: 173, 174: 174, 175: 175, 176: 176, 177: 177, 178: 178, 179: 179, 180: 180, 181: 181, 182: 182, 183: 183, 184: 184, 185: 185, 186: 186, 187: 187, 188: 188, 189: 189, 190: 190, 191: 191, 192: 192, 193: 193, 194: 194, 195: 195, 196: 196, 197: 197, 198: 198, 199: 199}\n"
     ]
    }
   ],
   "source": [
    "loaders, recall_ks = get_loaders(batch_size, test_batch_size, num_workers, pin_memory, sampler, recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de779e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(loaders.query_novel.dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "5e3951a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5396"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaders.train.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f1fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loaders.pool.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c4db367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2594"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaders.query.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "7cff552c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df35e75d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b320b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'resnet50'\n",
    "pretrained = True  # use a pretrained model from torchvision\n",
    "num_features = 2048 # dimensionality of the features produced by the feature extractor\n",
    "dropout = 0.5\n",
    "norm_layer = None  # use a normalization layer (batchnorm or layernorm) for the features\n",
    "# norm_layer = 'batch'\n",
    "remap = False  # remap features through a linear layer\n",
    "detach = False  # detach features before feeding to the classification layer. Prevents training of the feature extractor with cross-entropy.\n",
    "normalize = False  # normalize the features\n",
    "set_bn_eval = True  # set bn in eval mode even in training\n",
    "normalize_weight = False  # normalize the weights of the classification layer\n",
    "\n",
    "model = get_model(loaders.num_classes, arch, pretrained, num_features, \n",
    "                  norm_layer, detach, remap, normalize, normalize_weight,\n",
    "                  set_bn_eval, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "493988a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (norm_layer): Identity()\n",
       "  (remap): Identity()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (classifier): Linear(in_features=2048, out_features=100, bias=True)\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('checkpoints/resnet50_cub.pt'))\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cedbc78e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_Metrics(loss=None, accuracy=0.0, recall={'l2': {1: 80.55, 2: 87.87, 4: 92.27, 8: 95.63, 16: 97.65, 32: 98.84}, 'cosine': {1: 81.49, 2: 88.2, 4: 93.17, 8: 96.3, 16: 98.06, 32: 98.99}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, loaders.query_novel, recall=recall_ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f64f8",
   "metadata": {},
   "source": [
    "## Threshold selection using training data (query within training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "0f2acb59",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def evaluate_full(model: nn.Module,\n",
    "             query_loader: DataLoader,\n",
    "             gallery_loader: Optional[DataLoader] = None,\n",
    "             xent: bool = False,\n",
    "             recall: Optional[List[int]] = None,\n",
    "             threshold_ls: Optional[List[float]] = None) -> _Metrics:\n",
    "    \n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    to_device = lambda x: x.to(device, non_blocking=True)\n",
    "    all_query_labels = []\n",
    "    all_query_features = []\n",
    "    all_gallery_features = None\n",
    "    all_gallery_labels = None\n",
    "    xent_losses = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, labels, _ in tqdm(query_loader, desc='Extracting query features', leave=False, ncols=80):\n",
    "            batch, labels = map(to_device, (batch, labels))\n",
    "            logits, features = model(batch)\n",
    "\n",
    "            all_query_labels.append(labels)\n",
    "            if recall is not None:\n",
    "                all_query_features.append(features)\n",
    "            if xent:\n",
    "                xent_losses.append(F.cross_entropy(logits, labels, reduction='none'))\n",
    "            all_predictions.append(logits.argmax(1))\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        all_query_labels = torch.cat(all_query_labels, 0)\n",
    "        if recall is not None:\n",
    "            all_query_features = torch.cat(all_query_features, 0)\n",
    "            recall_function = partial(\n",
    "                recall_at_ks_full, query_features=all_query_features, query_labels=all_query_labels, ks=recall,\n",
    "                gallery_features=all_gallery_features, gallery_labels=all_gallery_labels\n",
    "            )\n",
    "            recalls = {}\n",
    "            precisions = {}\n",
    "            for ts in threshold_ls:\n",
    "                recalls['cosine_'+str(ts)], precisions['cosine_'+str(ts)] = recall_function(cosine=True, threshold=ts)\n",
    "\n",
    "    return recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "a5193738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "recall_func, precision_func = evaluate_full(model, loaders.train, recall=[1, 3, 5, 10], \n",
    "                                            threshold_ls=np.arange(0.0, 0.9, 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "a22aa882",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111759193516629\n",
      "0.9111759193516629\n",
      "0.9111759193516629\n",
      "0.9111759193516629\n",
      "0.9111759193516629\n",
      "0.9111759193516629\n",
      "0.9111759193516629\n",
      "0.9111759193516629\n",
      "0.9111759193516629\n",
      "0.9111759193516629\n",
      "0.9111821195831478\n",
      "0.9111573184401998\n",
      "0.9111578351290273\n",
      "0.9111515055827086\n",
      "0.9111495307014285\n",
      "0.9111227516694406\n",
      "0.9111134442101302\n",
      "0.9108969667823473\n",
      "0.911276610887253\n",
      "0.9107601638277227\n",
      "0.9110273502456241\n",
      "0.9092185190107489\n",
      "0.9050053215467948\n",
      "0.8987656140924484\n",
      "0.8902610184138525\n",
      "0.8734260722924937\n",
      "0.8537864242437783\n",
      "0.8294577853718488\n",
      "0.7910799452476268\n",
      "0.7491892061843327\n",
      "0.6976094531589049\n",
      "0.6356483661559511\n",
      "0.5629665690713394\n",
      "0.4795412453330218\n",
      "0.4019329534420133\n",
      "0.3263567047095337\n",
      "0.24346859099997636\n",
      "0.16617334339226184\n",
      "0.10732015782836661\n",
      "0.06800468874937764\n",
      "0.03366511701234608\n",
      "0.013391612533689866\n",
      "0.006137813951236101\n",
      "0.002417933893808402\n",
      "0.0007439732217254465\n"
     ]
    }
   ],
   "source": [
    "for ts in np.arange(0.0, 0.9, 0.02):\n",
    "    recall =  np.mean([np.mean(recall_func['cosine_{}'.format(ts)][i]) for i in [1,3,5,10]])\n",
    "    precision = np.mean([np.mean(precision_func['cosine_{}'.format(ts)][i]) for i in [1,3,5,10]])\n",
    "#     print('Threshold {:.2f}'.format(ts), Precision {}'.format(recall, precision))\n",
    "    print(precision)\n",
    "#     print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff69f95",
   "metadata": {},
   "source": [
    "## Get FP, FN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37540fd",
   "metadata": {},
   "source": [
    "- What are the FPs, FNs from pooled set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a99c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_loader = loaders.pool # unlabelled pool\n",
    "gallery_loader = loaders.train_noshuffle # train loader with no shuffling\n",
    "recall = recall_ks # TOchange\n",
    "ts = {'cub':0.64, 'cars':0.4, 'sop':0.5, 'inshop':0.52}['cub'] # TOchange\n",
    "device = 'cuda'\n",
    "to_device = lambda x: x.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00aa4068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 784.00 MiB (GPU 0; 11.78 GiB total capacity; 1.14 GiB already allocated; 540.69 MiB free; 1.17 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-00972a21c04f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Extracting query features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mall_query_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metric-learning/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ruofan/dml_cross_entropy/models/base_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ruofan/dml_cross_entropy/models/architectures/resnet.py\u001b[0m in \u001b[0;36mfeature_extractor\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metric-learning/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metric-learning/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metric-learning/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2056\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   2057\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2058\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2059\u001b[0m     )\n\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 0; 11.78 GiB total capacity; 1.14 GiB already allocated; 540.69 MiB free; 1.17 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "all_query_labels = []\n",
    "all_query_features = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, labels, _ in tqdm(query_loader, desc='Extracting query features', leave=False, ncols=80):\n",
    "        batch, labels = map(to_device, (batch, labels))\n",
    "        logits, features = model(batch)\n",
    "\n",
    "        all_query_labels.append(labels)\n",
    "        all_query_features.append(features)\n",
    "        all_predictions.append(logits.argmax(1))\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "all_query_labels = torch.cat(all_query_labels, 0)\n",
    "all_query_features = torch.cat(all_query_features, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2fe24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gallery_features = []\n",
    "all_gallery_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, labels, _ in tqdm(gallery_loader, desc='Extracting gallery features', leave=False, ncols=80):\n",
    "        batch, labels = map(to_device, (batch, labels))\n",
    "        features = model(batch)[1]\n",
    "\n",
    "        all_gallery_labels.append(labels)\n",
    "        all_gallery_features.append(features)\n",
    "\n",
    "all_gallery_labels = torch.cat(all_gallery_labels, 0)\n",
    "all_gallery_features = torch.cat(all_gallery_features, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4926cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([x.item() for x in all_query_labels]) - set([x.item() for x in all_gallery_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6814f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_query_features, 'checkpoints/cub_query_feat.pt')\n",
    "torch.save(all_query_labels, 'checkpoints/cub_query_label.pt')\n",
    "torch.save(all_gallery_features, 'checkpoints/cub_gallery_feat.pt') # or train feat\n",
    "torch.save(all_gallery_labels, 'checkpoints/cub_gallery_label.pt') # or train label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gallery_features = torch.load('checkpoints/inshop_gallery_feat.pt')\n",
    "all_gallery_labels = torch.load('checkpoints/inshop_gallery_label.pt') # or train label\n",
    "all_query_labels = torch.load('checkpoints/inshop_query_label.pt')\n",
    "all_query_features = torch.load('checkpoints/inshop_query_feat.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4490a562",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "recall_function = partial(\n",
    "    fp_fn_eval, query_features=all_query_features, query_labels=all_query_labels, ks=recall,\n",
    "    gallery_features=all_gallery_features, gallery_labels=all_gallery_labels\n",
    ")\n",
    "fns, fps = recall_function(cosine=True, threshold=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_samples = np.asarray(query_loader.dataset.samples)[np.where(fns == True)[0]]\n",
    "fp_samples = np.asarray(query_loader.dataset.samples)[np.where(fps == True)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c6d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_query_features = np.asarray(all_query_features)[np.where(fns == True)[0]]\n",
    "fp_query_features = np.asarray(all_query_features)[np.where(fps == True)[0]]\n",
    "fn_query_labels = np.asarray(all_query_labels)[np.where(fns == True)[0]]\n",
    "fp_query_labels = np.asarray(all_query_labels)[np.where(fps == True)[0]]\n",
    "\n",
    "normal_query_features = np.asarray(all_query_features)[np.where((fps == False) & (fns == False))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35eeefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(fn_query_features) + len(fp_query_features) + len(normal_query_features) == len(query_loader.dataset.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed7503c",
   "metadata": {},
   "source": [
    "- Can we detect them by looking at distance to training classes' centroid ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65852f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = torch.zeros(max(all_gallery_labels.numpy())+1, len(all_gallery_features))\n",
    "# M[all_gallery_labels, torch.arange(all_gallery_features.shape[0])] = 1 # one-hot map\n",
    "# M = torch.nn.functional.normalize(M, p=1, dim=1) # normalize to have each label of sum 1\n",
    "# centroids = torch.mm(M, all_gallery_features) # mean for each label\n",
    "# centroids = F.normalize(centroids, p=2, dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_M = torch.zeros(max(all_gallery_labels.numpy())+1, len(all_gallery_features))\n",
    "# full_M[all_gallery_labels, torch.arange(all_gallery_features.shape[0])] = 1 # one-hot map\n",
    "# each_centroids = torch.mm(full_M.T, torch.from_numpy(centroids)) # centroids for each obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b35fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# covs = []\n",
    "# mus = []\n",
    "\n",
    "# for label in tqdm(set(all_gallery_labels.numpy())):\n",
    "    \n",
    "#     select_gallery_features = all_gallery_features[torch.where(all_gallery_labels == label)[0]]\n",
    "#     select_centroids = each_centroids[torch.where(all_gallery_labels == label)[0]]\n",
    "    \n",
    "#     cov = np.cov(select_gallery_features.numpy(), rowvar=False)\n",
    "#     covs.append(cov)\n",
    "#     mus.append(select_centroids[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49177fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mus = np.asarray(mus)\n",
    "# covs = np.asarray(covs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1690d0",
   "metadata": {},
   "source": [
    "- Normal query to centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahan distance\n",
    "# query2gallery = []\n",
    "# for i in tqdm(range(len(mus))):\n",
    "#     dist = np.dot(np.dot((normal_query_features-mus[i][None, ...]), np.linalg.pinv(covs[i])), \n",
    "#                          (normal_query_features-mus[i][None, ...]).T)\n",
    "#     dist = dist.diagonal()\n",
    "#     query2gallery.append(dist)\n",
    "\n",
    "# query2gallery = np.asarray(query2gallery)\n",
    "# query2gallery = query2gallery.min(0) # distance to nearest centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max, Margin to centroids\n",
    "# normal_query_features = F.normalize(torch.from_numpy(normal_query_features), p=2, dim=1).numpy()\n",
    "# dist = np.dot(normal_query_features, centroids.T)\n",
    "# query2gallery = dist.max(0)\n",
    "# ind = np.argsort(dist, axis=1)\n",
    "# sorted_dist = np.take_along_axis(dist, ind, axis=1)\n",
    "# margin_query2gallery = sorted_dist[:, -1] - sorted_dist[:, -2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef22cbcb",
   "metadata": {},
   "source": [
    "- Mutual information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cb2d38",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{equation} \\label{eq1}\n",
    "\\begin{split}\n",
    "& I(Y_{train} \\cup Y_{selected} ; \\hat{Z}_{train} \\cup \\hat{Z}_{selected})  \\\\\n",
    "& \\approx I(Y_{train} \\cup \\hat{Y}_{selected} ; \\hat{Z}_{train} \\cup \\hat{Z}_{selected}) \\\\\n",
    "& = H(\\hat{Z}_{train} \\cup \\hat{Z}_{selected}) - H(\\hat{Z}_{train} \\cup \\hat{Z}_{selected} | Y_{train} \\cup \\hat{Y}_{selected}) \\\\\n",
    "& = H(\\hat{Z}_{train} \\cup \\hat{Z}_{selected}) - \\sum_{\\hat{y}}{\\sum_{y}{H(\\hat{Z}_{train} \\cup \\hat{Z}_{selected} | Y = y, \\hat{Y} = \\hat{y}) p(y) p(\\hat{y})}} \\\\\n",
    "& \\approx \\frac{d}{(N'-1)N'} \\sum_{i=1}^{N+1}{\\sum_{j=1}^{N+1}{logD_{ij}^2}} - \\sum_{\\hat{y}}{\\sum_{y}[{ \\frac{d}{(S'_{y}-1)S'_{y}}\\sum_{i=1}^{y_i=y}{\\sum_{j=1}^{y_j=y}{logD_{ij}^2}}] p(y) p(\\hat{y})}} \\\\ \\\\\n",
    "& \\text{where } \\quad N' = N + 1 \\text{ (assume one sample is selected}) \\\\\n",
    "& \\text{where } \\quad S_k = \\sum_i{\\mathbb{1}(y_i = k)} \\\\\n",
    "& \\text{where } \\quad S'_k = \\sum_i{\\mathbb{1}(y_i = k)} + 1 \\text{ (assume one sample is selected}) \\\\\n",
    "& \\text{where } \\quad p_{\\hat{y}}(k) = \\frac{exp(z_i^Tc_k)}{\\sum_{j}{exp(z_i^Tc_j)}} \\\\\n",
    "& \\text{where } \\quad p_y(k) = \\frac{S_k}{N}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute similarity matrix\n",
    "# z_train = F.normalize(all_gallery_features, p=2, dim=1).numpy()\n",
    "# z_pool = F.normalize(all_query_features, p=2, dim=1).numpy()\n",
    "# Sij = 2 - 2 * np.dot(z_train, z_pool.T) # \n",
    "\n",
    "# # empirical estimate of p(y) estimated from training set\n",
    "# (unique, counts) = np.unique(all_gallery_labels, return_counts=True)\n",
    "# py = counts / np.sum(counts)\n",
    "\n",
    "# # predicted distribution of p(yhat) for each unlabelled data\n",
    "# # M = torch.zeros(max(all_gallery_labels.numpy())+1, len(z_train))\n",
    "# M = torch.zeros(len(unique), len(z_train))\n",
    "# M[np.asarray([np.where(unique==x.item())[0].item() for x in all_gallery_labels]), torch.arange(z_train.shape[0])] = 1 # one-hot map\n",
    "# M = torch.nn.functional.normalize(M, p=1, dim=1) # normalize to have each label of sum 1\n",
    "# centroids = torch.mm(M, torch.from_numpy(z_train)) # mean for each label\n",
    "# centroids = F.normalize(centroids, p=2, dim=1).numpy() # should normalize otherwise experience overflow problem\n",
    "\n",
    "# zc = np.dot(z_pool, centroids.T)\n",
    "# temperature = 1\n",
    "# pyhat = np.exp(zc / temperature) / np.sum(np.exp(zc / temperature), axis=1, keepdims=True)\n",
    "\n",
    "# # compute entropy of Z\n",
    "# Dij = Sij # take distance between THIS example w.r.t gallery set\n",
    "# d = z_train.shape[1]\n",
    "# Hz_s = np.sum(np.log(Dij), axis=0) * d / (len(z_train)*(len(z_train)+1))\n",
    "\n",
    "# # compute conditional entropy of Z|Y\n",
    "# # M = np.zeros((max(all_gallery_labels.numpy())+1, len(z_train)))\n",
    "# M = np.zeros((len(unique), len(z_train)))\n",
    "# M[np.asarray([np.where(unique==x.item())[0].item() for x in all_gallery_labels]), np.arange(z_train.shape[0])] = 1 # one-hot map\n",
    "# category_sum = np.dot(M, np.log(Dij))\n",
    "# category_Hz = category_sum * d * (1/((counts+1) * len(z_train))).reshape(-1, 1)\n",
    "\n",
    "# cond_Hz = np.dot(category_Hz.T, pyhat.T) \n",
    "# cond_Hz_s = cond_Hz.diagonal()\n",
    "\n",
    "# # get fn, fp, normal corresponding entries\n",
    "# normal_Hz = np.asarray(Hz_s)[np.where((fps == False) & (fns == False))[0]]\n",
    "# fp_Hz = np.asarray(Hz_s)[np.where((fps == True))[0]]\n",
    "# fn_Hz = np.asarray(Hz_s)[np.where((fns == True))[0]]\n",
    "\n",
    "# normal_Hz_cond = np.asarray(cond_Hz_s)[np.where((fps == False) & (fns == False))[0]]\n",
    "# fp_Hz_cond = np.asarray(cond_Hz_s)[np.where((fps == True))[0]]\n",
    "# fn_Hz_cond = np.asarray(cond_Hz_s)[np.where((fns == True))[0]]\n",
    "\n",
    "# normal_info = normal_Hz - normal_Hz_cond\n",
    "# fp_info = fp_Hz - fp_Hz_cond\n",
    "# fn_info = fn_Hz - fn_Hz_cond\n",
    "\n",
    "# plt.hist(fn_Hz, label='FN', bins=50, alpha=0.5)\n",
    "# plt.hist(normal_Hz, label='Normal', bins=50, alpha=0.5)\n",
    "# plt.hist(fp_Hz , label='FP', bins=50, alpha=0.5)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(fn_Hz_cond, label='FN', bins=50, alpha=0.5)\n",
    "# plt.hist(normal_Hz_cond, label='Normal', bins=50, alpha=0.5)\n",
    "# plt.hist(fp_Hz_cond , label='FP', bins=50, alpha=0.5)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(fn_info, label='FN', bins=50, alpha=0.5)\n",
    "# plt.hist(normal_info, label='Normal', bins=50, alpha=0.5)\n",
    "# plt.hist(fp_info , label='FP', bins=50, alpha=0.5)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c687a",
   "metadata": {},
   "source": [
    "- FN query to centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d92e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahan distance\n",
    "# fn_query2gallery = []\n",
    "# for i in tqdm(range(len(mus))):\n",
    "#     dist = np.dot(np.dot((fn_query_features-mus[i][None, ...]), np.linalg.pinv(covs[i])), \n",
    "#                          (fn_query_features-mus[i][None, ...]).T)\n",
    "#     dist = dist.diagonal()\n",
    "#     fn_query2gallery.append(dist)\n",
    "# fn_query2gallery = np.asarray(fn_query2gallery)\n",
    "# fn_query2gallery = fn_query2gallery.min(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6dba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max, Margin to centroids\n",
    "# fn_query_features = F.normalize(torch.from_numpy(fn_query_features), p=2, dim=1).numpy()\n",
    "# dist = np.dot(fn_query_features, centroids.T)\n",
    "# fn_query2gallery = dist.max(0)\n",
    "# ind = np.argsort(dist, axis=1)\n",
    "# sorted_dist = np.take_along_axis(dist, ind, axis=1)\n",
    "# fn_margin_query2gallery = sorted_dist[:, -1] - sorted_dist[:, -2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76702e9e",
   "metadata": {},
   "source": [
    "- FP query to centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d62386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahan distance\n",
    "# fp_query2gallery = []\n",
    "# for i in tqdm(range(len(mus))):\n",
    "#     dist = np.dot(np.dot((fp_query_features-mus[i][None, ...]), np.linalg.pinv(covs[i])), \n",
    "#                          (fp_query_features-mus[i][None, ...]).T)\n",
    "#     dist = dist.diagonal()\n",
    "#     fp_query2gallery.append(dist)\n",
    "# fp_query2gallery = np.asarray(fp_query2gallery)\n",
    "# fp_query2gallery = fp_query2gallery.min(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d98fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max, Margin to centroids\n",
    "# fp_query_features = F.normalize(torch.from_numpy(fp_query_features), p=2, dim=1).numpy()\n",
    "# dist = np.dot(fp_query_features, centroids.T)\n",
    "# fp_query2gallery = dist.max(0)\n",
    "# ind = np.argsort(dist, axis=1)\n",
    "# sorted_dist = np.take_along_axis(dist, ind, axis=1)\n",
    "# fp_margin_query2gallery = sorted_dist[:, -1] - sorted_dist[:, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5793a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fn_query2gallery, label='FN', bins=50, alpha=0.5)\n",
    "plt.hist(query2gallery, label='Normal', bins=50, alpha=0.5)\n",
    "plt.hist(fp_query2gallery, label='FP', bins=50, alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48058097",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fn_query2gallery, label='FN', bins=50, alpha=0.5)\n",
    "plt.hist(query2gallery, label='Normal', bins=50, alpha=0.5)\n",
    "plt.hist(fp_query2gallery, label='FP', bins=50, alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fn_margin_query2gallery, label='FN', bins=50, alpha=0.5)\n",
    "plt.hist(margin_query2gallery, label='Normal', bins=50, alpha=0.5)\n",
    "plt.hist(fp_margin_query2gallery, label='FP', bins=50, alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ae313",
   "metadata": {},
   "source": [
    "- Can we detect through reconstruction error ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798bc382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from models.vae_ingredient import model_ingredient, get_model\n",
    "in_channels = 3\n",
    "latent_dim = 512\n",
    "arch = 'AE'\n",
    "\n",
    "encoder_model = get_model(arch, in_channels, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd75765",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model.load_state_dict(torch.load('checkpoints/AE_sop_vae.pt'))\n",
    "encoder_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f40d6e",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_reconstructed_error = torch.tensor([])\n",
    "with torch.no_grad():\n",
    "    for batch, labels, _ in tqdm(query_loader, desc='Extracting query features', leave=False, ncols=80):\n",
    "        batch, labels = map(to_device, (batch, labels))\n",
    "        z, _, reconstructed = encoder_model(batch)\n",
    "        reconstructed_error = F.binary_cross_entropy(reconstructed, batch, reduction='none').mean(1).mean(1).mean(1)\n",
    "        \n",
    "        print(reconstructed_error.shape)\n",
    "        all_reconstructed_error = torch.cat((all_reconstructed_error, reconstructed_error.detach().cpu()), dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_reconstructed_error = np.asarray(all_reconstructed_error)[np.where(fns == True)[0]]\n",
    "fp_reconstructed_error = np.asarray(all_reconstructed_error)[np.where(fps == True)[0]]\n",
    "normal_reconstructed_error = np.asarray(all_reconstructed_error)[np.where((fps == False) & (fns == False))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d5bab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_reconstructed_error = torch.tensor([])\n",
    "with torch.no_grad():\n",
    "    for batch, labels, _ in tqdm(loaders.train_noshuffle, desc='Extracting query features', leave=False, ncols=80):\n",
    "        batch, labels = map(to_device, (batch, labels))\n",
    "        z, _, reconstructed = encoder_model(batch)\n",
    "        reconstructed_error = F.binary_cross_entropy(reconstructed, batch, reduction='none').mean(1).mean(1).mean(1)\n",
    "        print(reconstructed_error.shape)\n",
    "        train_reconstructed_error = torch.cat((all_reconstructed_error, reconstructed_error.detach().cpu()), dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_reconstructed_error.numpy(), bins=50, label='Training', alpha=0.3)\n",
    "plt.hist(fn_reconstructed_error, bins=50, label='FN', alpha=0.7)\n",
    "plt.hist(fp_reconstructed_error, bins=50, label='FP', alpha=0.7)\n",
    "plt.hist(normal_reconstructed_error, bins=50, label='Normal', alpha=0.7)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be340e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "333.7364196777344px",
    "left": "877.9212036132812px",
    "right": "20px",
    "top": "120px",
    "width": "354.2527160644531px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
